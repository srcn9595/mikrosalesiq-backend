# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ services/intent_api/main.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from fastapi import FastAPI, Request
from datetime import datetime
import os, json, pathlib
from openai import OpenAI
from langfuse import Langfuse
from dotenv import load_dotenv
import logging
import re
from typing import List  
from datetime import datetime, timedelta
from openai.types.chat import ChatCompletionMessageToolCall

ROOT_DIR   = pathlib.Path(__file__).parent
CONFIG_DIR = ROOT_DIR / "config"
load_dotenv(ROOT_DIR / ".env")

# â”€â”€ statik dosyalar ---------------------------------------------------------
SYSTEM_PROMPT = (CONFIG_DIR / "system_prompt.txt").read_text(encoding="utf-8")
TOOL_MANIFEST = json.loads((ROOT_DIR / "tool_manifest.json").read_text())
_REL_RE = re.compile(r"{today([+-]\d+)([dwmy])}")
# â”€â”€ FastAPI + OpenAI + Langfuse --------------------------------------------
app = FastAPI()

langfuse = Langfuse(
    public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
    secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
    host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com"),
)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ call-level algÄ±sÄ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# intent dÃ¼zeyi haritasÄ±
INTENT_LEVEL_MAP = {
    "cleaned_transcript": "call",
    "file_path": "call",
    "duration": "call",
    "call_date": "call",
    "agent_email": "call",
    "agent_name": "call",
    "call_insights": "call",
    "contact_email": "customer",
    "contact_name": "customer",
    "customer_num": "customer",
    "opportunity_stage": "customer",
    "product_lookup": "customer",
    "lead_source": "customer",
    "close_date": "customer",
    "created_date": "customer",
    "lost_reason": "customer",
    "get_call_metrics":"customer",
    "get_conversion_probability": "customer",
    "get_risk_score": "customer",
    "get_next_steps": "customer",
    "get_audio_analysis_commentary": "customer",
    "get_sentiment_analysis": "customer"
}

def is_call_level_intent(intent: str) -> bool:
    return INTENT_LEVEL_MAP.get(intent) == "call"

def pipeline_is_call_level(pipeline: list[dict]) -> bool:
    """
    Pipelineâ€™da $unwind "$calls" VARSA veya
    herhangi bir stage 'calls.' ile baÅŸlayan alan kullanÄ±yorsa TRUE dÃ¶ner.
    """
    for stage in pipeline:
        # 1) $unwind
        if "$unwind" in stage:
            uw = stage["$unwind"]
            if (isinstance(uw, str)  and uw.startswith("$calls")) or \
               (isinstance(uw, dict) and uw.get("path") == "$calls"):
                return True

        # 2) $match / $project / $sort vs.
        for op in ("$match", "$project", "$sort"):
            if op in stage and any(k.startswith("calls.") for k in stage[op]):
                return True
    return False

def ensure_call_id(pipeline: list[dict], intent: str) -> list[dict]:
    """
    EÄŸer intent call-level ise ve pipeline da Ã¶yle gÃ¶rÃ¼nÃ¼yorsa
    $project aÅŸamasÄ±na call_id ekler.
    """
    if not is_call_level_intent(intent):
        return pipeline

    if not pipeline_is_call_level(pipeline):
        return pipeline

    for st in pipeline:
        if "$project" in st:
            st["$project"].setdefault("call_id", "$calls.call_id")
            st["$project"].setdefault("_id", 0)
            return pipeline

    pipeline.append({"$project": {"_id": 0, "call_id": "$calls.call_id"}})
    return pipeline

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _resolve_relative_dates(text: str) -> str:
    """
    {todayÂ±Nd}, {todayÂ±Nw}, {todayÂ±Nm}, {todayÂ±Ny} makrolarÄ±nÄ±
    gerÃ§ek ISO-8601 tarihlere Ã§evirir.
    """
    def _sub(m):
        offset = int(m.group(1))
        unit   = m.group(2)
        base   = datetime.utcnow().date()

        if unit == "d":
            real = base + timedelta(days=offset)
        elif unit == "w":
            real = base + timedelta(weeks=offset)
        elif unit == "m":
            # Ay iÃ§in kaba â‰ˆ30 gÃ¼n (geliÅŸmiÅŸ ihtiyaÃ§ta dateutil.relativedelta kullanÄ±n)
            real = base + timedelta(days=30 * offset)
        elif unit == "y":
            real = base + timedelta(days=365 * offset)
        else:
            return m.group(0)           # bilinmeyen; dokunma

        return real.isoformat()
    return _REL_RE.sub(_sub, text)

CANON = {
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€ Ä°Ã§erik alanlarÄ± â”€â”€â”€â”€â”€â”€â”€â”€â”€
    r"(Ã¶zet|analiz|summary)":                "summary",
    r"(profil|profile|mÃ¼ÅŸteri profili)":     "customer_profile",
    r"(skor|puan|score)":                    "sales_scores",
    r"(Ã¶neri|recommendation|tavsiye)":       "recommendations",
    r"(transkript|metin|clean text)":        "cleaned_transcript",
    r"(sÃ¼re|duration|kaÃ§.?dk|kaÃ§.?sn)":      "duration",

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€ CRM alanlarÄ± â”€â”€â”€â”€â”€â”€â”€â”€â”€
    r"(paket|Ã¼rÃ¼n|module|product)":          "product_lookup",
    r"(stage|aÅŸama|fÄ±rsat.?aÅŸamasÄ±)":        "opportunity_stage",
    r"(kaynak|lead source)":                 "lead_source",
    r"(close date|kapanÄ±ÅŸ.?tarihi)":         "close_date",
    r"(lost reason|kaybedilme.?sebebi)":     "lost_reason",
    r"(contact.?email|iletiÅŸim.?eposta)":    "contact_email",
    r"(contact.?name|iletiÅŸim.?adÄ±)":        "contact_name",
}



def extract_fields(query: str) -> List[str]:
    found = [
        canon
        for pattern, canon in CANON.items()
        if re.search(pattern, query, re.I)      # â€¼ï¸ re.escape YOK
    ]
    return list(dict.fromkeys(found))


def build_messages(user_query: str) -> list[dict]:
    today_iso = datetime.utcnow().date().isoformat()

    # statik dosyalar
    schema_json   = (CONFIG_DIR / "schema_registry.json").read_text()
    heuristics_md = (CONFIG_DIR / "heuristics.md").read_text()
    examples_md   = (CONFIG_DIR / "prompt_examples.md").read_text()
    intents_json  = (CONFIG_DIR / "intents.json").read_text()

    # Ã¶nce {today} makrosu
    sys_prompt = SYSTEM_PROMPT.replace("{today}", today_iso)

    # prompt dosyalarÄ±nÄ±n hepsine aynÄ± iÅŸlemi uygulamak gerekebilir
    # (Ã¶rneklerde de {today-â€¦} geÃ§iyorsa)
    sys_prompt = _resolve_relative_dates(sys_prompt)
    examples_md = _resolve_relative_dates(examples_md)

    wanted_fields = extract_fields(user_query)
    fields_hint   = "**User-requested fields:** " + (
        ", ".join(wanted_fields) if wanted_fields else "(default)"
    )

    sys_prompt = (
        sys_prompt
        .replace("{{fields_hint}}",      fields_hint)
        .replace("{{schema_registry}}",  schema_json)
        .replace("{{heuristics}}",       heuristics_md)
        .replace("{{prompt_examples}}",  examples_md)
        .replace("{{intents_json}}",     intents_json)
    )

    # son olarak â€œJSON dÃ¶ndÃ¼râ€ hatÄ±rlatÄ±cÄ±sÄ±
    sys_prompt = "You MUST answer in valid JSON.\n\n" + sys_prompt

    return [
        {"role": "system", "content": sys_prompt},
        {"role": "user",   "content": user_query},
    ]


def normalize_plan(raw):
    """
    OpenAI cevabÄ±nÄ± tek listeye indirger â€“ list[{name,arguments}]
    """

    # 0ï¸âƒ£  Model yalnÄ±zca **tek** fonksiyon Ã§aÄŸrÄ±sÄ± dÃ¶ndÃ¼rdÃ¼yse
    #     {"name": "...", "arguments": {...}}
    if isinstance(raw, dict) and "name" in raw and "arguments" in raw:
        return [raw]                       #  â†  YENÄ° SATIR

    # â‘   DÃ¼z liste
    if isinstance(raw, list):
        if len(raw) == 1 and raw[0].get("name") == "multi_tool_use.parallel":
            return raw[0]["arguments"]["tool_uses"]
        return raw

    # â‘¡  2024-03 chat formatÄ±
    if "tool_calls" in raw:
        return raw["tool_calls"]

    # â‘¢  parallel wrapper
    if raw.get("name") == "multi_tool_use.parallel":
        return raw["arguments"]["tool_uses"]

    # â‘£  {'plan':[...]} + iÃ§i parallel
    if "plan" in raw and isinstance(raw["plan"], list):
        lst = raw["plan"]
        if len(lst) == 1 and lst[0].get("name") == "multi_tool_use.parallel":
            return lst[0]["parameters"]["tool_uses"]
        return lst

    # â‘¤  {'tool_call': {...}}
    if "tool_call" in raw:
        return [raw["tool_call"]]

    raise ValueError("Unknown plan format")

def tidy(step: dict) -> dict:
    """
    Executorâ€™un beklediÄŸi forma Ã§evirir:
      {'name': '...', 'arguments': {...}}
    """
    # 0) nested parallel â†’ iÃ§indekileri Ã§Ã¶z
    if step.get("name") == "multi_tool_use.parallel":
        return [tidy(s) for s in step["parameters"]["tool_uses"]]

    # 1) zaten doÄŸru form
    if "name" in step and "arguments" in step:
        step["name"] = step["name"].removeprefix("functions.")
        if "intent" in step:
            step["intent"] = step["intent"]
        return step

    # 2) OpenAI parallel elemanÄ±
    if "recipient_name" in step and "parameters" in step:
        name = step["recipient_name"].removeprefix("functions.")
        step["name"] = step["name"].removeprefix("functions.")
        return {"name": name, "arguments": step["parameters"]}

    # 3) Basit {'name', 'parameters'} formu
    if "name" in step and "parameters" in step:
        return {"name": step["name"], "arguments": step["parameters"]}

    raise ValueError(f"Unknown step format: {step}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ endpoint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/analyze")
async def analyze(req: Request):
    query = (await req.json()).get("query", "")

    # â‘  Root span: intent_detection
    with langfuse.start_as_current_span(
        name="intent_detection",
        input={"query": query},
        metadata={"service": "intent_api"}
    ) as root_span:

        try:
            # â‘¡ Generation span: openai.plan
            with langfuse.start_as_current_generation(
                name="openai.plan",
                model="gpt-4o-mini",
                input={"messages": build_messages(query)}
            ) as gen:

                resp = client.chat.completions.create(
                    model="gpt-4o-mini",
                    tools=TOOL_MANIFEST,
                    messages=build_messages(query),
                    response_format={"type": "json_object"},
                    temperature=0,
                )

                msg_raw = resp.choices[0].message
                if msg_raw.tool_calls:                       # yeni SDK yolu
                     raw = [
                        {                                    # normalize_plan / tidy beklediÄŸi format
                            "name": tc.function.name,
                            "arguments": json.loads(tc.function.arguments)
                  }
                   for tc in msg_raw.tool_calls         # tc: ChatCompletionMessageToolCall
                ]
                else:                                        # eski (content) yolu
                    raw = json.loads(msg_raw.content)
                try:
                    steps   = normalize_plan(raw)
                except Exception as e:
                        logging.error("normalize_plan â€“ ham cevap: %s", raw)   # ðŸ‘ˆ
                        raise    

                plan = []
                for s in steps:
                    t = tidy(s)
                    if isinstance(t, list):
                        plan.extend(t)
                        continue

                    if t["name"] == "mongo_aggregate":
                        pl = t["arguments"].get("pipeline", [])
                        intent = t.get("intent", "")
                        t["arguments"]["pipeline"] = ensure_call_id(pl, intent)

                    plan.append(t)


                # â‘¢ Generation spanâ€™a sonucu kaydet
                gen.update(output={"plan": plan})

            # â‘£ Root spanâ€™a sonucu da ekleyebilirsiniz
            root_span.update(output={"plan": plan})
            return {"plan": plan}

        except Exception as exc:
            root_span.update(output={"error": str(exc)})
            # Ä°sterseniz hatayÄ± yeniden fÄ±rlatÄ±n veya JSON dÃ¶nÃ¼n
            return {"plan": [], "error": str(exc), "query": query}

    # â‘¤ Flush (opsiyonel)
    langfuse.flush()

